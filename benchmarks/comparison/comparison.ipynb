{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e301884-7a01-44cb-bca8-d35c5d29353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from collections import defaultdict, deque\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List, Dict, Tuple, Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1286b701-0c2c-4f35-b97e-f1fc79cdf11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_coefficient(values: List[float]) -> float:\n",
    "    if not values:\n",
    "        return 0.0\n",
    "    sorted_vals = sorted(values)\n",
    "    n = len(values)\n",
    "    cumvals = np.cumsum(sorted_vals)\n",
    "    if cumvals[-1] == 0:\n",
    "        return 0.0\n",
    "    gini = (n + 1 - 2 * np.sum(cumvals) / cumvals[-1]) / n\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e371797c-cbb6-4de9-b0c4-a6a7f67b3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erdos_renyi_graph(n: int, p: float, rng: random.Random) -> Dict[int, Set[int]]:\n",
    "    adj = {i: set() for i in range(n)}\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if rng.random() < p:\n",
    "                adj[i].add(j)\n",
    "                adj[j].add(i)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef3d0ae-2027-402e-a4cb-473157c66d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_without(items: List[int], k: int, rng: random.Random) -> List[int]:\n",
    "    if k >= len(items):\n",
    "        return list(items)\n",
    "    return rng.sample(items, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "168ef10d-1889-480a-8816-badbe67c11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_per_event(n: int, msg_size_bytes: int, alpha: float = 1.5) -> Dict[str, Dict[str, float]]:\n",
    "    mqtt_messages = 1 + max(n-1, 0)\n",
    "    mqtt_bytes = mqtt_messages * msg_size_bytes\n",
    "    coap_messages = 2\n",
    "    coap_bytes = coap_messages * msg_size_bytes\n",
    "    ln_n = max(math.log(max(n, 2)), 1.0)\n",
    "    redundancy = alpha * ln_n\n",
    "    gossip_messages = redundancy * max(n-1, 0)\n",
    "    gossip_bytes = gossip_messages * msg_size_bytes\n",
    "    return {\n",
    "        \"MQTT\": {\"messages\": mqtt_messages, \"bytes\": mqtt_bytes, \"redundancy\": 1.0},\n",
    "        \"CoAP\": {\"messages\": coap_messages, \"bytes\": coap_bytes, \"redundancy\": 1.0},\n",
    "        \"Gossip\": {\"messages\": gossip_messages, \"bytes\": gossip_bytes, \"redundancy\": redundancy},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d33a2433-2850-484a-8298-22bdedf8e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_gossip(adj: Dict[int, Set[int]], alive: Set[int], seed_sources: Set[int], fanout: int, rounds: int, rng: random.Random):\n",
    "    informed_round = {i: math.inf for i in adj.keys()}\n",
    "    for s in seed_sources:\n",
    "        if s in alive:\n",
    "            informed_round[s] = 0\n",
    "    coverage_history = [len([1 for k,v in informed_round.items() if v < math.inf])]\n",
    "    last_r = 0\n",
    "    for r in range(1, rounds+1):\n",
    "        new_informed = set()\n",
    "        for u in list(informed_round.keys()):\n",
    "            if informed_round[u] < math.inf:\n",
    "                neighbors = [v for v in adj[u] if v in alive]\n",
    "                if not neighbors:\n",
    "                    continue\n",
    "                choices = sample_without(neighbors, fanout, rng)\n",
    "                for v in choices:\n",
    "                    if informed_round[v] == math.inf:\n",
    "                        informed_round[v] = r\n",
    "                        new_informed.add(v)\n",
    "        coverage_history.append(len([1 for k,v in informed_round.items() if v < math.inf]))\n",
    "        if not new_informed:\n",
    "            last_r = r\n",
    "            break\n",
    "    if last_r == 0:\n",
    "        last_r = rounds\n",
    "    return informed_round, last_r, coverage_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcdb5fcd-6382-4850-b0bc-aa36d5d2bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_mqtt_coverage(n: int, alive: Set[int], broker_alive: bool, link_up_prob_to_broker: float, publishers: Set[int], rng: random.Random) -> int:\n",
    "    if not broker_alive:\n",
    "        return len([p for p in publishers if p in alive])\n",
    "    coverage = 0\n",
    "    for node in range(n):\n",
    "        if node in alive:\n",
    "            if rng.random() < link_up_prob_to_broker:\n",
    "                coverage += 1\n",
    "    return coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4010f85f-6e7b-4052-aabd-1b6705111c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def failure_resilience_experiment(n: int = 200, edge_prob: float = 0.05, fanout: int = 3, alpha: float = 1.5, failure_rates: List[float] = None, link_fail_rate: float = 0.1, trials: int = 20, rng_seed: int = 42):\n",
    "    if failure_rates is None:\n",
    "        failure_rates = [0.0, 0.1, 0.2, 0.3, 0.5]\n",
    "    rng = random.Random(rng_seed)\n",
    "    results = []\n",
    "    for p_fail in failure_rates:\n",
    "        gossip_cov = []\n",
    "        gossip_rounds = []\n",
    "        mqtt_cov = []\n",
    "        for t in range(trials):\n",
    "            adj = erdos_renyi_graph(n, edge_prob, rng)\n",
    "            alive = {i for i in range(n) if rng.random() >= p_fail}\n",
    "            publisher = rng.randrange(n)\n",
    "            publishers = {publisher}\n",
    "            rounds = max(1, int(round(alpha * math.log(max(n, 2)))))\n",
    "            informed_round, last_r, cov_hist = simulate_gossip(adj=adj, alive=alive, seed_sources=publishers, fanout=fanout, rounds=rounds, rng=rng)\n",
    "            cov = len([1 for v in informed_round.values() if v < math.inf])\n",
    "            gossip_cov.append(cov / max(1, len(alive)))\n",
    "            gossip_rounds.append(last_r)\n",
    "            broker_alive = (rng.random() >= p_fail)\n",
    "            link_up_prob = 1.0 - link_fail_rate\n",
    "            cov_mqtt = simulate_mqtt_coverage(n=n, alive=alive, broker_alive=broker_alive, link_up_prob_to_broker=link_up_prob, publishers=publishers, rng=rng)\n",
    "            mqtt_cov.append(cov_mqtt / max(1, len(alive)))\n",
    "        results.append({\n",
    "            \"failure_rate\": p_fail,\n",
    "            \"gossip_coverage_mean\": float(np.mean(gossip_cov)),\n",
    "            \"gossip_coverage_p10\": float(np.percentile(gossip_cov, 10)),\n",
    "            \"gossip_coverage_p90\": float(np.percentile(gossip_cov, 90)),\n",
    "            \"gossip_rounds_median\": float(np.median(gossip_rounds)),\n",
    "            \"mqtt_coverage_mean\": float(np.mean(mqtt_cov)),\n",
    "            \"mqtt_coverage_p10\": float(np.percentile(mqtt_cov, 10)),\n",
    "            \"mqtt_coverage_p90\": float(np.percentile(mqtt_cov, 90)),\n",
    "        })\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a3308f1-d038-4e89-8619-e65cf6037b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_merge_experiment(n: int = 200, edge_prob: float = 0.04, fanout: int = 3, alpha: float = 1.5, partition_rounds: int = 5, post_merge_rounds: int = 10, rng_seed: int = 123) -> pd.DataFrame:\n",
    "    rng = random.Random(rng_seed)\n",
    "    nA = n // 2\n",
    "    nB = n - nA\n",
    "    nodesA = list(range(nA))\n",
    "    nodesB = list(range(nA, nA + nB))\n",
    "    adj = {i: set() for i in range(n)}\n",
    "    adjA = erdos_renyi_graph(nA, edge_prob, rng)\n",
    "    adjB = erdos_renyi_graph(nB, edge_prob, rng)\n",
    "    for u in adjA:\n",
    "        for v in adjA[u]:\n",
    "            adj[u].add(v)\n",
    "            adj[v].add(u)\n",
    "    for u in adjB:\n",
    "        gu = u + nA\n",
    "        for v in adjB[u]:\n",
    "            gv = v + nA\n",
    "            adj[gu].add(gv)\n",
    "            adj[gv].add(gu)\n",
    "    alive = set(range(n))\n",
    "    fanout_val = fanout\n",
    "    rounds_total = partition_rounds + post_merge_rounds\n",
    "    knows_A = {i: False for i in range(n)}\n",
    "    knows_B = {i: False for i in range(n)}\n",
    "    seedA = rng.choice(nodesA)\n",
    "    seedB = rng.choice(nodesB)\n",
    "    knows_A[seedA] = True\n",
    "    knows_B[seedB] = True\n",
    "    hist = []\n",
    "    def round_spread(knowledge: Dict[int, bool], local_adj: Dict[int, Set[int]]):\n",
    "        newly = set()\n",
    "        for u in range(n):\n",
    "            if knowledge[u] and u in alive:\n",
    "                neigh = [v for v in local_adj[u] if v in alive]\n",
    "                choices = sample_without(neigh, fanout_val, rng)\n",
    "                for v in choices:\n",
    "                    if not knowledge[v]:\n",
    "                        knowledge[v] = True\n",
    "                        newly.add(v)\n",
    "        return newly\n",
    "    for r in range(1, partition_rounds + 1):\n",
    "        round_spread(knows_A, adj)\n",
    "        round_spread(knows_B, adj)\n",
    "        covA = sum(1 for k in knows_A.values() if k)\n",
    "        covB = sum(1 for k in knows_B.values() if k)\n",
    "        covBoth = sum(1 for i in range(n) if knows_A[i] and knows_B[i])\n",
    "        hist.append({\"round\": r, \"phase\": \"partition\", \"cov_A\": covA, \"cov_B\": covB, \"cov_both\": covBoth})\n",
    "    for i in range(nA):\n",
    "        for j in range(nB):\n",
    "            if rng.random() < (edge_prob / 5):\n",
    "                gi = i\n",
    "                gj = j + nA\n",
    "                adj[gi].add(gj)\n",
    "                adj[gj].add(gi)\n",
    "    for r in range(partition_rounds + 1, rounds_total + 1):\n",
    "        round_spread(knows_A, adj)\n",
    "        round_spread(knows_B, adj)\n",
    "        covA = sum(1 for k in knows_A.values() if k)\n",
    "        covB = sum(1 for k in knows_B.values() if k)\n",
    "        covBoth = sum(1 for i in range(n) if knows_A[i] and knows_B[i])\n",
    "        hist.append({\"round\": r, \"phase\": \"post-merge\", \"cov_A\": covA, \"cov_B\": covB, \"cov_both\": covBoth})\n",
    "    df_hist = pd.DataFrame(hist)\n",
    "    return df_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9924ca9-096d-48a4-97c3-7be44e9df9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_balance_experiment(n: int = 200, edge_prob: float = 0.05, fanout: int = 3, alpha: float = 1.5, publishers: int = 20, rng_seed: int = 7) -> pd.DataFrame:\n",
    "    rng = random.Random(rng_seed)\n",
    "    adj = erdos_renyi_graph(n, edge_prob, rng)\n",
    "    pubs = set(rng.sample(range(n), publishers))\n",
    "    rounds = max(1, int(round(alpha * math.log(max(n, 2)))))\n",
    "    send_counts_gossip = [0] * n\n",
    "    informed = {p: set([p]) for p in pubs}\n",
    "    for r in range(1, rounds + 1):\n",
    "        for p in pubs:\n",
    "            new_informed = set()\n",
    "            for u in list(informed[p]):\n",
    "                neigh = list(adj[u])\n",
    "                choices = sample_without(neigh, fanout, rng)\n",
    "                for v in choices:\n",
    "                    send_counts_gossip[u] += 1\n",
    "                    if v not in informed[p]:\n",
    "                        new_informed.add(v)\n",
    "            informed[p].update(new_informed)\n",
    "    send_counts_mqtt = [0] * n\n",
    "    broker = rng.randrange(n)\n",
    "    for p in pubs:\n",
    "        send_counts_mqtt[p] += 1\n",
    "    send_counts_mqtt[broker] += (n - 1) * len(pubs)\n",
    "    df = pd.DataFrame({\"node\": list(range(n)), \"send_gossip\": send_counts_gossip, \"send_mqtt\": send_counts_mqtt})\n",
    "    df[\"gini_gossip\"] = gini_coefficient(df[\"send_gossip\"].tolist())\n",
    "    df[\"gini_mqtt\"] = gini_coefficient(df[\"send_mqtt\"].tolist())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ec8d6-b580-46d0-a0cb-4fc3250256c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f1c65-e6aa-4894-80cc-5d92f3532894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Parameters\n",
    "N = 200\n",
    "MSG_SIZE = 50\n",
    "ALPHA = 1.5\n",
    "FANOUT = 3\n",
    "EDGE_PROB = 0.05\n",
    "\n",
    "# 1) Load per event for a range of N\n",
    "ns = [10, 25, 50, 100, 200, 400]\n",
    "records = []\n",
    "for n in ns:\n",
    "    rec = load_per_event(n, MSG_SIZE, alpha=ALPHA)\n",
    "    for proto, vals in rec.items():\n",
    "        records.append({\n",
    "            \"N\": n,\n",
    "            \"protocol\": proto,\n",
    "            \"messages_per_event\": vals[\"messages\"],\n",
    "            \"bytes_per_event\": vals[\"bytes\"],\n",
    "            \"redundancy_factor\": vals[\"redundancy\"],\n",
    "        })\n",
    "df_load = pd.DataFrame(records)\n",
    "\n",
    "# 2) Failure resilience\n",
    "df_fail = failure_resilience_experiment(n=N, edge_prob=EDGE_PROB, fanout=FANOUT, alpha=ALPHA, failure_rates=[0.0, 0.1, 0.2, 0.3, 0.5], link_fail_rate=0.1, trials=25, rng_seed=1234)\n",
    "\n",
    "# 3) Partition & merge\n",
    "df_pm = partition_merge_experiment(n=N, edge_prob=EDGE_PROB, fanout=FANOUT, alpha=ALPHA, partition_rounds=6, post_merge_rounds=12, rng_seed=99)\n",
    "\n",
    "# 4) Load balance\n",
    "df_lb = load_balance_experiment(n=N, edge_prob=EDGE_PROB, fanout=FANOUT, alpha=ALPHA, publishers=25, rng_seed=321)\n",
    "\n",
    "from caas_jupyter_tools import display_dataframe_to_user\n",
    "display_dataframe_to_user(\"Load per event (MQTT vs CoAP vs Gossip)\", df_load)\n",
    "display_dataframe_to_user(\"Failure resilience results (coverage stats)\", df_fail)\n",
    "display_dataframe_to_user(\"Partition & merge convergence history\", df_pm)\n",
    "display_dataframe_to_user(\"Load balance per-node send counts\", df_lb)\n",
    "\n",
    "# Plots\n",
    "\n",
    "# Plot 1: Bytes per event vs N\n",
    "plt.figure()\n",
    "for proto in [\"MQTT\", \"CoAP\", \"Gossip\"]:\n",
    "    x = np.asarray([r[\"N\"] for r in records if r[\"protocol\"] == proto], dtype=float)\n",
    "    y = np.asarray([r[\"bytes_per_event\"] for r in records if r[\"protocol\"] == proto], dtype=float)\n",
    "    plt.plot(x, y, marker=\"o\", label=proto)\n",
    "plt.xlabel(\"Number of nodes (N)\")\n",
    "plt.ylabel(\"Bytes per event\")\n",
    "plt.title(\"Bytes per event vs N\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/mnt/data/plot_bytes_per_event.png\", dpi=160)\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Messages per event vs N (log scale on y)\n",
    "plt.figure()\n",
    "for proto in [\"MQTT\", \"CoAP\", \"Gossip\"]:\n",
    "    x = np.asarray([r[\"N\"] for r in records if r[\"protocol\"] == proto], dtype=float)\n",
    "    y = np.asarray([r[\"messages_per_event\"] for r in records if r[\"protocol\"] == proto], dtype=float)\n",
    "    plt.plot(x, y, marker=\"o\", label=proto)\n",
    "plt.xlabel(\"Number of nodes (N)\")\n",
    "plt.ylabel(\"Messages per event\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Messages per event vs N (log y)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/mnt/data/plot_messages_per_event.png\", dpi=160)\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Failure resilience — coverage vs failure rate\n",
    "plt.figure()\n",
    "x = np.asarray(df_fail[\"failure_rate\"].tolist(), dtype=float)\n",
    "g_mean = np.asarray(df_fail[\"gossip_coverage_mean\"].tolist(), dtype=float)\n",
    "m_mean = np.asarray(df_fail[\"mqtt_coverage_mean\"].tolist(), dtype=float)\n",
    "g_p10 = np.asarray(df_fail[\"gossip_coverage_p10\"].tolist(), dtype=float)\n",
    "g_p90 = np.asarray(df_fail[\"gossip_coverage_p90\"].tolist(), dtype=float)\n",
    "m_p10 = np.asarray(df_fail[\"mqtt_coverage_p10\"].tolist(), dtype=float)\n",
    "m_p90 = np.asarray(df_fail[\"mqtt_coverage_p90\"].tolist(), dtype=float)\n",
    "\n",
    "plt.plot(x, g_mean, marker=\"o\", label=\"Gossip mean\")\n",
    "plt.plot(x, m_mean, marker=\"o\", label=\"MQTT mean\")\n",
    "plt.fill_between(x, g_p10, g_p90, alpha=0.2, label=\"Gossip p10–p90\")\n",
    "plt.fill_between(x, m_p10, m_p90, alpha=0.2, label=\"MQTT p10–p90\")\n",
    "plt.xlabel(\"Node failure rate\")\n",
    "plt.ylabel(\"Coverage (fraction of alive nodes)\")\n",
    "plt.title(\"Failure resilience: coverage vs failures\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/mnt/data/plot_failure_resilience.png\", dpi=160)\n",
    "plt.show()\n",
    "\n",
    "# Plot 4: Partition & merge — coverage over rounds\n",
    "plt.figure()\n",
    "x2 = np.asarray(df_pm[\"round\"].tolist(), dtype=float)\n",
    "yA = np.asarray(df_pm[\"cov_A\"].tolist(), dtype=float)\n",
    "yB = np.asarray(df_pm[\"cov_B\"].tolist(), dtype=float)\n",
    "yBoth = np.asarray(df_pm[\"cov_both\"].tolist(), dtype=float)\n",
    "plt.plot(x2, yA, label=\"Update A coverage\")\n",
    "plt.plot(x2, yB, label=\"Update B coverage\")\n",
    "plt.plot(x2, yBoth, label=\"Both updates known\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Nodes covered\")\n",
    "plt.title(\"Partition & merge: convergence after healing\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/mnt/data/plot_partition_merge.png\", dpi=160)\n",
    "plt.show()\n",
    "\n",
    "# Plot 5: Load balance — Gini coefficients\n",
    "plt.figure()\n",
    "gini_gossip = gini_coefficient(df_lb[\"send_gossip\"].tolist())\n",
    "gini_mqtt = gini_coefficient(df_lb[\"send_mqtt\"].tolist())\n",
    "plt.bar([\"Gossip\", \"MQTT\"], [gini_gossip, gini_mqtt])\n",
    "plt.ylabel(\"Gini coefficient (send load)\")\n",
    "plt.title(\"Load balance: per-node send-load inequality\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/mnt/data/plot_load_balance_gini.png\", dpi=160)\n",
    "plt.show()\n",
    "\n",
    "# Save CSV outputs for download\n",
    "df_load.to_csv(\"/mnt/data/load_per_event.csv\", index=False)\n",
    "df_fail.to_csv(\"/mnt/data/failure_resilience.csv\", index=False)\n",
    "df_pm.to_csv(\"/mnt/data/partition_merge.csv\", index=False)\n",
    "df_lb.to_csv(\"/mnt/data/load_balance.csv\", index=False)\n",
    "\n",
    "print(\"Files saved:\")\n",
    "print(\"- /mnt/data/plot_bytes_per_event.png\")\n",
    "print(\"- /mnt/data/plot_messages_per_event.png\")\n",
    "print(\"- /mnt/data/plot_failure_resilience.png\")\n",
    "print(\"- /mnt/data/plot_partition_merge.png\")\n",
    "print(\"- /mnt/data/plot_load_balance_gini.png\")\n",
    "print(\"- /mnt/data/load_per_event.csv\")\n",
    "print(\"- /mnt/data/failure_resilience.csv\")\n",
    "print(\"- /mnt/data/partition_merge.csv\")\n",
    "print(\"- /mnt/data/load_balance.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
